{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Neural Networks for identifying the authorship of a Twitter post\n",
    "\n",
    "Deep Learning Programming Project, summer semester 2019\n",
    "\n",
    "Instructor: Dr. Hanhe Lin\n",
    "\n",
    "By Simon Suckut and Adam Norris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Our idea is to use a convolutional neural network to classify twitter posts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "#other imports....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Our dataset was gathered from public profiles on Twitter...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_twitter_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "#     \"\"\"\n",
    "#     Load the dataset and perform preprocessing to prepare\n",
    "#     it for classification.  \n",
    "#     \"\"\"\n",
    "#     # Load the raw data\n",
    "#     twitter_dir = '../../data/twitter'\n",
    "#     X_train, y_train, X_test, y_test = load_twitter(twitter_dir)\n",
    "    \n",
    "#     # subsample the data\n",
    "#     mask = list(range(num_training, num_training + num_validation))\n",
    "#     X_val = X_train[mask]\n",
    "#     y_val = y_train[mask]\n",
    "#     mask = list(range(num_training))\n",
    "#     X_train = X_train[mask]\n",
    "#     y_train = y_train[mask]\n",
    "#     mask = list(range(num_test))\n",
    "#     X_test = X_test[mask]\n",
    "#     y_test = y_test[mask]\n",
    "#     mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "#     X_dev = X_train[mask]\n",
    "#     y_dev = y_train[mask]\n",
    "    \n",
    "#     # Normalize the data\n",
    "#     X_train /= 255\n",
    "#     X_val /= 255\n",
    "#     X_test /= 255\n",
    "#     X_dev /= 255\n",
    "    \n",
    "#     return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# # Invoke the above function to get our data.\n",
    "# X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_twitter_data()\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# num_classes = 10\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# print('Train data shape: ', X_train.shape)\n",
    "# print('Train labels shape: ', y_train.shape)\n",
    "# print('Validation data shape: ', X_val.shape)\n",
    "# print('Validation labels shape: ', y_val.shape)\n",
    "# print('Test data shape: ', X_test.shape)\n",
    "# print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Preprocessing description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Model Description: We use a convolutional neural network to...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape = (32, 32, 3)\n",
    "\n",
    "\n",
    "model = None\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, train and test model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "learning_rate = 0.01\n",
    "decay=1e-6\n",
    "momentum=0.9\n",
    "#etc.....\n",
    "\n",
    "\n",
    "\n",
    "#Compile Model\n",
    "sgd = SGD(lr=learning_rate, decay=1e-6, momentum=0.9) \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Callbacks\n",
    "#cp_callback = keras.callbacks.ModelCheckpoint('../../model.hdf5',save_weights_only=True,verbose=1)\n",
    "\n",
    "#Train Model\n",
    "history= model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(X_val, y_val),callbacks=[cp_callback])\n",
    "\n",
    "#Test Model and Print results\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Training and Validation \n",
    "\n",
    "Below is a graphical representation of the training and validation loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curve here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Network here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
